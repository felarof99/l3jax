{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y5OeTiryEcoX"
   },
   "source": [
    "# Fine-tuning Gemma2 2B model on Roadrunner with JAX, Flax.\n",
    "\n",
    "We have adopted the Gemma notebook from Google Deepmind to use HuggingFace's libraries, added support for doing **model parallel training** and simplified the setup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5m81VQOqEcoX"
   },
   "source": [
    "## Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "def import_local_module(module_path: str):\n",
    "    sys.path.append('')\n",
    "    module = importlib.import_module(module_path)\n",
    "    return importlib.reload(module)\n",
    "\n",
    "# Imports felafax trainer_engine\n",
    "setup = import_local_module(\"trainer_engine.setup\")\n",
    "setup.setup_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch\n",
    "!pip install torch --index-url https://download.pytorch.org/whl/cpu -q\n",
    "\n",
    "# JAX ecosystem\n",
    "!pip install --upgrade jax -q\n",
    "!pip install jax[tpu] -f https://storage.googleapis.com/jax-releases/libtpu_releases.html -q\n",
    "!pip install jax-lorax -q\n",
    "!pip install \"flax[all]\" -q\n",
    "!pip install --upgrade optax==0.2.2\n",
    "\n",
    "# Machine learning libraries\n",
    "!pip install --no-cache-dir transformers==4.43.3\n",
    "!pip install --no-cache-dir datasets==2.18.0\n",
    "!pip install qax -q\n",
    "\n",
    "# Utility libraries\n",
    "!pip install --upgrade einops\n",
    "!pip install --upgrade tqdm\n",
    "!pip install --upgrade requests\n",
    "!pip install --upgrade typing-extensions\n",
    "!pip install --upgrade sentencepiece\n",
    "!pip install --upgrade pydantic\n",
    "!pip install --upgrade cloudpickle\n",
    "!pip install gcsfs\n",
    "\n",
    "# Web development libraries\n",
    "!pip install --upgrade fastapi\n",
    "!pip install --upgrade uvicorn\n",
    "!pip install --upgrade gradio\n",
    "\n",
    "# Configuration management\n",
    "!pip install --upgrade ml_collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "globals().update(setup.setup_imports())\n",
    "\n",
    "utils = import_local_module(\"trainer_engine.utils\")\n",
    "llama_model = import_local_module(\"trainer_engine.llama_model\")\n",
    "checkpoint_lib = import_local_module(\"trainer_engine.checkpoint_lib\")\n",
    "training_pipeline = import_local_module(\"trainer_engine.training_pipeline\")\n",
    "convert_to_hf = import_local_module(\"trainer_engine.convert_to_hf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Input your HF username, token and download model weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the base model you want to fine-tune üëá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a supported model from above list to use!\n",
    "MODEL_NAME = \"meta-llama/Meta-Llama-3.1-8B\"\n",
    "JAX_MODEL_NAME = \"felafax/llama-3.1-8B-JAX\"\n",
    "model_ckpt_path = \"/mnt/persistent-disk/hf/models--felafax--llama-3.1-8B-JAX/snapshots/ebca17f216e4c02e0f31cc47264a9d65a4f5b9a9/llama3.1_8b_serialized.flax\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input your HuggingFaceü§ó username and token below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "INPUT: Please provide your HUGGINGFACE_USERNAME:  felarof01\n",
      "INPUT: Please provide your HUGGINGFACE_TOKEN:  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\n"
     ]
    }
   ],
   "source": [
    "hf_model_name = MODEL_NAME\n",
    "HUGGINGFACE_USERNAME = input(\"INPUT: Please provide your HUGGINGFACE_USERNAME: \")\n",
    "HUGGINGFACE_TOKEN = input(\"INPUT: Please provide your HUGGINGFACE_TOKEN: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(\n",
    "    MODEL_NAME, \n",
    "    token=HUGGINGFACE_TOKEN)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_NAME, \n",
    "    token=HUGGINGFACE_TOKEN,\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 3 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [02:41<00:00, 53.70s/it]\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "model_path = snapshot_download(repo_id=JAX_MODEL_NAME, token=HUGGINGFACE_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: prepare the dataset\n",
    "\n",
    "For this project, we're utilizing the refined **Alpaca dataset**, curated by yahma. This dataset is a carefully filtered selection of 52,000 entries from the original Alpaca collection. Feel free to substitute this section with your own data preparation code if you prefer.\n",
    "\n",
    "It's crucial to include the EOS_TOKEN (End of Sequence Token) in your tokenized output. Failing to do so may result in endless generation loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(*, tokenizer, batch_size=1, seq_length=32, max_examples=None):\n",
    "    # Define Alpaca prompt template\n",
    "    alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "    \n",
    "    ### Instruction: {}\n",
    "    \n",
    "    ### Input: {}\n",
    "    \n",
    "    ### Response: {}\"\"\"\n",
    "    \n",
    "    EOS_TOKEN = tokenizer.eos_token\n",
    "    \n",
    "    # Defines formatting function.\n",
    "    def _format_prompts(examples):\n",
    "        instructions = examples[\"instruction\"]\n",
    "        inputs = examples[\"input\"]\n",
    "        outputs = examples[\"output\"]\n",
    "        texts = []\n",
    "        for instruction, input, output in zip(instructions, inputs, outputs):\n",
    "            text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n",
    "            texts.append(text)\n",
    "        return {\"text\": texts}\n",
    "\n",
    "    def _tokenize(examples):\n",
    "        tokenized = tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=seq_length+1)\n",
    "        return {\n",
    "            'input_tokens': [input_id[:-1] for input_id in tokenized['input_ids']],\n",
    "            'target_tokens': [input_id[1:] for input_id in tokenized['input_ids']],\n",
    "            'loss_masks': [input_id[1:] for input_id in tokenized['attention_mask']]\n",
    "        }\n",
    "\n",
    "    def _custom_collate_fn(batch: List[Dict[str, Any]]) -> Dict[str, jnp.ndarray]:\n",
    "        \"\"\"\n",
    "        Collates batch items and converts PyTorch tensors to JAX arrays.\n",
    "        Applies default_data_collator, then converts tensors to JAX format.\n",
    "        \"\"\"\n",
    "        collated = default_data_collator(batch)\n",
    "        jax_batch = {}\n",
    "        for key, value in collated.items():\n",
    "            jax_batch[key] = jnp.array(value.numpy()) if isinstance(value, torch.Tensor) else value\n",
    "        \n",
    "        return jax_batch\n",
    "\n",
    "    # Load and preprocess the dataset\n",
    "    dataset = load_dataset(\"yahma/alpaca-cleaned\", split=\"train\")\n",
    "    if max_examples:\n",
    "        dataset = dataset.select(range(max_examples))\n",
    "    dataset = dataset.map(_format_prompts, batched=True)\n",
    "\n",
    "    # Create train and test dataset.\n",
    "    ds = dataset.train_test_split(test_size=0.15)\n",
    "    for split in ['train', 'test']:\n",
    "        ds[split] = ds[split].map(_tokenize, batched=True, remove_columns=dataset.column_names)\n",
    "\n",
    "    # Create DataLoaders\n",
    "    dataloader_args = dict(shuffle=True, batch_size=batch_size, collate_fn=_custom_collate_fn)\n",
    "    train_dataloader = torch.utils.data.DataLoader(ds['train'], **dataloader_args)\n",
    "    test_dataloader = torch.utils.data.DataLoader(ds['test'], **dataloader_args)\n",
    "\n",
    "    return train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Uncomment below code ‚¨áÔ∏è if you'd like to run and test üíØ your dataset pipeline.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 435/435 [00:00<00:00, 903.01 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 77/77 [00:00<00:00, 943.52 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tokens shape: (1, 32)\n",
      "Target mask shape: (1, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def test_dataset_pipeline(tokenizer):\n",
    "    \"\"\"Print shapes of first batch to verify dataset pipeline.\"\"\"\n",
    "    train_loader, _ = get_dataset(tokenizer=tokenizer, batch_size=1, seq_length=32, max_examples=512)\n",
    "    batch = next(iter(train_loader))\n",
    "    print(\"Input tokens shape:\", batch['input_tokens'].shape)\n",
    "    print(\"Target mask shape:\", batch['target_tokens'].shape)\n",
    "test_dataset_pipeline(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Train the model by configuring the hyperparameters below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "@chex.dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "    learning_rate: float = 1e-4\n",
    "    num_epochs: int = 1\n",
    "    max_steps: int | None = 5\n",
    "    batch_size: int = 32\n",
    "    seq_length: int = 64\n",
    "    dataset_size_limit: int | None = 512\n",
    "    print_every_n_steps: int = 1\n",
    "\n",
    "\n",
    "training_cfg = TrainingConfig()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: The **time-to-first step of training will be slow** because XLA takes time initially to compile the computational graph. However, once the compilation is complete, subsequent steps will run much faster using the compiled and cached graph, leveraging the full power of all TPU cores for accelerated training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure mesh\n",
    "devices = jax.devices()\n",
    "device_count = len(devices)\n",
    "device_mesh = mesh_utils.create_device_mesh((1, device_count, 1))\n",
    "mesh = Mesh(devices=device_mesh, axis_names=(\"dp\", \"fsdp\", \"mp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model and optimizer\n",
    "llama_config = llama_model.LlamaConfig(\"llama3_8b\")\n",
    "hf_pretrained_llama_config = llama_config.get_hf_pretrained_config(dict(llama_config.get_model_config()))\n",
    "\n",
    "model = llama_model.CausalLlamaModule(\n",
    "    hf_pretrained_llama_config,\n",
    "    dtype=jnp.float32,\n",
    "    param_dtype=jnp.float32,\n",
    ")\n",
    "optimizer = optax.sgd(training_cfg.learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 435/435 [00:00<00:00, 902.54 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 77/77 [00:00<00:00, 905.53 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Prepare dataset\n",
    "train_dataloader, val_dataloader = get_dataset(\n",
    "    tokenizer=tokenizer,\n",
    "    seq_length=training_cfg.seq_length,\n",
    "    max_examples=training_cfg.dataset_size_limit,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/persistent-disk/fax/llama3.1_8b_serialized.flax'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ckpt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading llama JAX model...\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Trainer\n",
    "trainer = training_pipeline.Trainer(\n",
    "    model=model,\n",
    "    model_ckpt_path=model_ckpt_path,\n",
    "    model_config=llama_config,\n",
    "    optimizer=optimizer,\n",
    "    training_config=training_cfg,\n",
    "    mesh=mesh,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0 of training...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "pjit in_shardings specification must be a tree prefix of the positional arguments tuple passed to the `pjit`-decorated function. In particular, pjit in_shardings must either be a None, a PartitionSpec, or a tuple of length equal to the number of positional arguments. But pjit in_shardings is the wrong length: got a tuple or list of length 4 for an args tuple of length 3.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[106], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmesh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/l3jax/l3jax/trainer_engine/training_pipeline.py:200\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, mesh, state, train_dataloader)\u001b[0m\n\u001b[1;32m    197\u001b[0m train_batch \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mdevice_put(train_batch,\n\u001b[1;32m    198\u001b[0m                              NamedSharding(mesh, PS()))\n\u001b[1;32m    199\u001b[0m sharded_rng \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mnext_rng()\n\u001b[0;32m--> 200\u001b[0m state, sharded_rng, metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msharded_train_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msharded_rng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_config\u001b[38;5;241m.\u001b[39mprint_every_n_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    205\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Step \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    206\u001b[0m     )\n",
      "    \u001b[0;31m[... skipping hidden 8 frame]\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/jax/_src/pjit.py:1075\u001b[0m, in \u001b[0;36mflatten_axis_resources\u001b[0;34m(what, tree, shardings, tupled_args)\u001b[0m\n\u001b[1;32m   1070\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1071\u001b[0m       msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Given the corresponding argument being \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1072\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassed, it looks like \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwhat\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m might need to be wrapped in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1073\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma singleton tuple.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1075\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1077\u001b[0m axis_tree \u001b[38;5;241m=\u001b[39m shardings\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;66;03m# Because we only have the `tree` treedef and not the full pytree here,\u001b[39;00m\n\u001b[1;32m   1080\u001b[0m \u001b[38;5;66;03m# we construct a dummy tree to compare against. Revise this in callers?\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: pjit in_shardings specification must be a tree prefix of the positional arguments tuple passed to the `pjit`-decorated function. In particular, pjit in_shardings must either be a None, a PartitionSpec, or a tuple of length equal to the number of positional arguments. But pjit in_shardings is the wrong length: got a tuple or list of length 4 for an args tuple of length 3."
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "state = trainer.train(mesh, trainer.train_state, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = os.path.dirname(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/persistent-disk/hf/models--felafax--llama-3.1-8B-JAX/snapshots/ebca17f216e4c02e0f31cc47264a9d65a4f5b9a9'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the model\n",
    "with mesh:\n",
    "    checkpointer.save_train_state_to_file(\n",
    "        train_state=state,\n",
    "        gather_fns=gather_fns,\n",
    "        path=os.path.join(model_dir, \"trained_llama.flax\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/l3jax/l3jax/trainer_engine/convert_to_hf.py\u001b[0m(39)\u001b[0;36mload_and_convert_checkpoint\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     37 \u001b[0;31m    \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflax_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStreamingCheckpointer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_trainstate_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     38 \u001b[0;31m    \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 39 \u001b[0;31m    \u001b[0mflax_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflax_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     40 \u001b[0;31m    \u001b[0mtorch_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     41 \u001b[0;31m    \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mflax_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  flax_params\n",
      "ipdb>  path\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'trainstate::/mnt/persistent-disk/hf/models--felafax--llama-3.1-8B-JAX/snapshots/ebca17f216e4c02e0f31cc47264a9d65a4f5b9a9/trained_llama.flax'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  quti\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** NameError: name 'quti' is not defined\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  quit\n"
     ]
    }
   ],
   "source": [
    "convert_to_hf.main([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = HfApi()\n",
    "api.upload_folder(\n",
    "    folder_path=\"/mnt/persistent-disk/easy/e2hf/\",\n",
    "    repo_id=\"felafax/llama3.1-8b-easylm-to-hf\",\n",
    "    repo_type=\"model\",\n",
    "    ignore_patterns=[\".*\"],\n",
    "    token=\"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\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "private_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
